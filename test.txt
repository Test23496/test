use std::collections::HashSet;
use std::sync::Arc;
use std::time::Duration;
use bytes::Bytes;
use k8s_openapi::api::core::v1::{ConfigMap, Namespace};
use k8s_openapi::apimachinery::pkg::apis::meta::v1::ObjectMeta;
use kube::{
    Api, Client, ResourceExt,
    api::{ListParams, PostParams, Patch, PatchParams},
    runtime::{
        controller::{Action, Controller as KubeController},
        watcher, reflector,
    },
};
use serde::{Deserialize, Serialize};
use tokio::sync::RwLock;
use tokio::time;
use x509_parser::prelude::*;

const CONFIG_MAP_NAMESPACE: &str = "kube-system";
const CONFIG_MAP_NAME: &str = "extension-apiserver-authentication";

/// Controller holds the running state for the controller
pub struct Controller {
    required_authentication_data: ClusterAuthenticationInfo,
    client: Client,
    config_map_api: Api<ConfigMap>,
    namespace_api: Api<Namespace>,
}

/// ClusterAuthenticationInfo holds the information that will included in public configmap.
#[derive(Clone, Default)]
pub struct ClusterAuthenticationInfo {
    /// ClientCA is the CA that can be used to verify the identity of normal clients
    pub client_ca: Option<Arc<dyn CAContentProvider>>,

    /// RequestHeaderUsernameHeaders are the headers used by this kube-apiserver to determine username
    pub request_header_username_headers: Option<Arc<dyn StringSliceProvider>>,
    /// RequestHeaderUIDHeaders are the headers used by this kube-apiserver to determine UID
    pub request_header_uid_headers: Option<Arc<dyn StringSliceProvider>>,
    /// RequestHeaderGroupHeaders are the headers used by this kube-apiserver to determine groups
    pub request_header_group_headers: Option<Arc<dyn StringSliceProvider>>,
    /// RequestHeaderExtraHeaderPrefixes are the headers used by this kube-apiserver to determine user.extra
    pub request_header_extra_header_prefixes: Option<Arc<dyn StringSliceProvider>>,
    /// RequestHeaderAllowedNames are the subjects allowed to act as a front proxy
    pub request_header_allowed_names: Option<Arc<dyn StringSliceProvider>>,
    /// RequestHeaderCA is the CA that can be used to verify the front proxy
    pub request_header_ca: Option<Arc<dyn CAContentProvider>>,
}

pub trait CAContentProvider: Send + Sync {
    fn current_ca_bundle_content(&self) -> Vec<u8>;
}

pub trait StringSliceProvider: Send + Sync {
    fn value(&self) -> Vec<String>;
}

struct StaticCAContent {
    name: String,
    content: Vec<u8>,
}

impl CAContentProvider for StaticCAContent {
    fn current_ca_bundle_content(&self) -> Vec<u8> {
        self.content.clone()
    }
}

struct StaticStringSlice {
    values: Vec<String>,
}

impl StringSliceProvider for StaticStringSlice {
    fn value(&self) -> Vec<String> {
        self.values.clone()
    }
}

impl Controller {
    /// NewClusterAuthenticationTrustController returns a controller that will maintain the kube-system configmap/extension-apiserver-authentication
    /// that holds information about how to aggregated apiservers are recommended (but not required) to configure themselves.
    pub fn new(
        required_authentication_data: ClusterAuthenticationInfo,
        client: Client,
    ) -> Self {
        let config_map_api: Api<ConfigMap> = Api::namespaced(client.clone(), CONFIG_MAP_NAMESPACE);
        let namespace_api: Api<Namespace> = Api::all(client.clone());

        Self {
            required_authentication_data,
            client,
            config_map_api,
            namespace_api,
        }
    }

    async fn sync_config_map(&self) -> Result<(), Box<dyn std::error::Error>> {
        let original_auth_config_map = match self.config_map_api.get(CONFIG_MAP_NAME).await {
            Ok(cm) => cm,
            Err(kube::Error::Api(err)) if err.code == 404 => {
                ConfigMap {
                    metadata: ObjectMeta {
                        namespace: Some(CONFIG_MAP_NAMESPACE.to_string()),
                        name: Some(CONFIG_MAP_NAME.to_string()),
                        ..Default::default()
                    },
                    data: None,
                    ..Default::default()
                }
            }
            Err(e) => return Err(Box::new(e)),
        };

        // keep the original to diff against later before updating
        let mut auth_config_map = original_auth_config_map.clone();

        let existing_authentication_info = get_cluster_authentication_info_for(
            original_auth_config_map.data.as_ref()
        )?;
        let combined_info = combined_cluster_authentication_info(
            existing_authentication_info,
            self.required_authentication_data.clone(),
        )?;
        auth_config_map.data = Some(get_config_map_data_for(&combined_info)?);

        if auth_config_map == original_auth_config_map {
            log::debug!("no changes to configmap");
            return Ok(());
        }
        log::info!(
            "writing updated authentication info to {} configmaps/{}",
            CONFIG_MAP_NAMESPACE,
            CONFIG_MAP_NAME
        );

        create_namespace_if_needed(&self.namespace_api, CONFIG_MAP_NAMESPACE).await?;
        write_config_map(&self.config_map_api, &auth_config_map).await?;

        Ok(())
    }

    /// Run the controller until stopped.
    pub async fn run(&self, workers: usize) -> Result<(), Box<dyn std::error::Error>> {
        log::info!("Starting cluster_authentication_trust_controller controller");

        let mut interval = time::interval(Duration::from_secs(60));
        loop {
            interval.tick().await;
            if let Err(e) = self.sync_config_map().await {
                log::error!("Failed to sync config map: {:?}", e);
            }
        }
    }

    /// Enqueue a method to allow separate control loops to cause the controller to trigger and reconcile content.
    pub async fn enqueue(&self) {
        if let Err(e) = self.sync_config_map().await {
            log::error!("Failed to sync config map: {:?}", e);
        }
    }
}

async fn create_namespace_if_needed(
    namespace_api: &Api<Namespace>,
    ns: &str,
) -> Result<(), Box<dyn std::error::Error>> {
    match namespace_api.get(ns).await {
        Ok(_) => {
            // the namespace already exists
            return Ok(());
        }
        Err(_) => {}
    }

    let new_ns = Namespace {
        metadata: ObjectMeta {
            name: Some(ns.to_string()),
            ..Default::default()
        },
        ..Default::default()
    };

    match namespace_api.create(&PostParams::default(), &new_ns).await {
        Ok(_) => Ok(()),
        Err(kube::Error::Api(err)) if err.code == 409 => Ok(()), // AlreadyExists
        Err(e) => Err(Box::new(e)),
    }
}

async fn write_config_map(
    config_map_api: &Api<ConfigMap>,
    required: &ConfigMap,
) -> Result<(), Box<dyn std::error::Error>> {
    let name = required.name_any();
    
    match config_map_api
        .replace(&name, &PostParams::default(), required)
        .await
    {
        Ok(_) => return Ok(()),
        Err(kube::Error::Api(err)) if err.code == 404 => {
            return match config_map_api.create(&PostParams::default(), required).await {
                Ok(_) => Ok(()),
                Err(e) => Err(Box::new(e)),
            };
        }
        Err(e) => {
            // If the configmap is too big, clear the entire thing and count on this controller (or another one) to add the correct data back.
            // We return the original error which causes the controller to re-queue.
            // Too big means
            //   1. request is so big the generic request catcher finds it
            //   2. the content is so large that that the server sends a validation error "Too long: must have at most 1048576 characters"
            if e.to_string().contains("too large") || 
               (e.to_string().contains("Invalid") && e.to_string().contains("Too long")) {
                if let Err(delete_err) = config_map_api.delete(&name, &Default::default()).await {
                    return Err(Box::new(delete_err));
                }
            }
            return Err(Box::new(e));
        }
    }
}

/// combinedClusterAuthenticationInfo combines two sets of authentication information into a new one
fn combined_cluster_authentication_info(
    lhs: ClusterAuthenticationInfo,
    rhs: ClusterAuthenticationInfo,
) -> Result<ClusterAuthenticationInfo, Box<dyn std::error::Error>> {
    let ret = ClusterAuthenticationInfo {
        request_header_allowed_names: combine_unique_string_slices(
            lhs.request_header_allowed_names.as_ref(),
            rhs.request_header_allowed_names.as_ref(),
        ),
        request_header_extra_header_prefixes: combine_unique_string_slices(
            lhs.request_header_extra_header_prefixes.as_ref(),
            rhs.request_header_extra_header_prefixes.as_ref(),
        ),
        request_header_group_headers: combine_unique_string_slices(
            lhs.request_header_group_headers.as_ref(),
            rhs.request_header_group_headers.as_ref(),
        ),
        request_header_username_headers: combine_unique_string_slices(
            lhs.request_header_username_headers.as_ref(),
            rhs.request_header_username_headers.as_ref(),
        ),
        request_header_uid_headers: combine_unique_string_slices(
            lhs.request_header_uid_headers.as_ref(),
            rhs.request_header_uid_headers.as_ref(),
        ),
        client_ca: combine_cert_lists(lhs.client_ca.as_ref(), rhs.client_ca.as_ref())?,
        request_header_ca: combine_cert_lists(
            lhs.request_header_ca.as_ref(),
            rhs.request_header_ca.as_ref(),
        )?,
    };

    Ok(ret)
}

fn get_config_map_data_for(
    authentication_info: &ClusterAuthenticationInfo,
) -> Result<std::collections::BTreeMap<String, String>, Box<dyn std::error::Error>> {
    let mut data = std::collections::BTreeMap::new();
    
    if let Some(client_ca) = &authentication_info.client_ca {
        let ca_bytes = client_ca.current_ca_bundle_content();
        if !ca_bytes.is_empty() {
            data.insert("client-ca-file".to_string(), String::from_utf8(ca_bytes)?);
        }
    }

    if authentication_info.request_header_ca.is_none() {
        return Ok(data);
    }

    if let Some(request_header_ca) = &authentication_info.request_header_ca {
        let ca_bytes = request_header_ca.current_ca_bundle_content();
        if !ca_bytes.is_empty() {
            // encoding errors aren't going to get better, so just fail on them.
            if let Some(headers) = &authentication_info.request_header_username_headers {
                data.insert(
                    "requestheader-username-headers".to_string(),
                    json_serialize_string_slice(&headers.value())?,
                );
            }

            // Note: Feature gate check for RemoteRequestHeaderUID would go here
            if let Some(uid_headers) = &authentication_info.request_header_uid_headers {
                if !uid_headers.value().is_empty() {
                    data.insert(
                        "requestheader-uid-headers".to_string(),
                        json_serialize_string_slice(&uid_headers.value())?,
                    );
                }
            }

            if let Some(group_headers) = &authentication_info.request_header_group_headers {
                data.insert(
                    "requestheader-group-headers".to_string(),
                    json_serialize_string_slice(&group_headers.value())?,
                );
            }

            if let Some(extra_prefixes) = &authentication_info.request_header_extra_header_prefixes {
                data.insert(
                    "requestheader-extra-headers-prefix".to_string(),
                    json_serialize_string_slice(&extra_prefixes.value())?,
                );
            }

            data.insert(
                "requestheader-client-ca-file".to_string(),
                String::from_utf8(ca_bytes)?,
            );

            if let Some(allowed_names) = &authentication_info.request_header_allowed_names {
                data.insert(
                    "requestheader-allowed-names".to_string(),
                    json_serialize_string_slice(&allowed_names.value())?,
                );
            }
        }
    }

    Ok(data)
}

fn get_cluster_authentication_info_for(
    data: Option<&std::collections::BTreeMap<String, String>>,
) -> Result<ClusterAuthenticationInfo, Box<dyn std::error::Error>> {
    let mut ret = ClusterAuthenticationInfo::default();

    let data = match data {
        Some(d) => d,
        None => return Ok(ret),
    };

    ret.request_header_group_headers = json_deserialize_string_slice(
        data.get("requestheader-group-headers").map(|s| s.as_str()),
    )?;
    ret.request_header_extra_header_prefixes = json_deserialize_string_slice(
        data.get("requestheader-extra-headers-prefix").map(|s| s.as_str()),
    )?;
    ret.request_header_allowed_names = json_deserialize_string_slice(
        data.get("requestheader-allowed-names").map(|s| s.as_str()),
    )?;
    ret.request_header_username_headers = json_deserialize_string_slice(
        data.get("requestheader-username-headers").map(|s| s.as_str()),
    )?;

    // Note: Feature gate check for RemoteRequestHeaderUID would go here
    ret.request_header_uid_headers = json_deserialize_string_slice(
        data.get("requestheader-uid-headers").map(|s| s.as_str()),
    )?;

    if let Some(ca_bundle) = data.get("requestheader-client-ca-file") {
        if !ca_bundle.is_empty() {
            ret.request_header_ca = Some(Arc::new(StaticCAContent {
                name: "existing".to_string(),
                content: ca_bundle.as_bytes().to_vec(),
            }));
        }
    }

    if let Some(ca_bundle) = data.get("client-ca-file") {
        if !ca_bundle.is_empty() {
            ret.client_ca = Some(Arc::new(StaticCAContent {
                name: "existing".to_string(),
                content: ca_bundle.as_bytes().to_vec(),
            }));
        }
    }

    Ok(ret)
}

fn json_serialize_string_slice(input: &[String]) -> Result<String, Box<dyn std::error::Error>> {
    Ok(serde_json::to_string(input)?)
}

fn json_deserialize_string_slice(
    input: Option<&str>,
) -> Result<Option<Arc<dyn StringSliceProvider>>, Box<dyn std::error::Error>> {
    match input {
        None | Some("") => Ok(None),
        Some(s) => {
            let out: Vec<String> = serde_json::from_str(s)?;
            Ok(Some(Arc::new(StaticStringSlice { values: out })))
        }
    }
}

fn combine_unique_string_slices(
    lhs: Option<&Arc<dyn StringSliceProvider>>,
    rhs: Option<&Arc<dyn StringSliceProvider>>,
) -> Option<Arc<dyn StringSliceProvider>> {
    let mut ret = Vec::new();
    let mut present = HashSet::new();

    if let Some(lhs) = lhs {
        for curr in lhs.value() {
            if !present.contains(&curr) {
                ret.push(curr.clone());
                present.insert(curr);
            }
        }
    }

    if let Some(rhs) = rhs {
        for curr in rhs.value() {
            if !present.contains(&curr) {
                ret.push(curr.clone());
                present.insert(curr);
            }
        }
    }

    if ret.is_empty() {
        None
    } else {
        Some(Arc::new(StaticStringSlice { values: ret }))
    }
}

fn combine_cert_lists(
    lhs: Option<&Arc<dyn CAContentProvider>>,
    rhs: Option<&Arc<dyn CAContentProvider>>,
) -> Result<Option<Arc<dyn CAContentProvider>>, Box<dyn std::error::Error>> {
    let mut certificates = Vec::new();

    if let Some(lhs) = lhs {
        let lhs_ca_bytes = lhs.current_ca_bundle_content();
        let lhs_cas = parse_certs_pem(&lhs_ca_bytes)?;
        certificates.extend(lhs_cas);
    }

    if let Some(rhs) = rhs {
        let rhs_ca_bytes = rhs.current_ca_bundle_content();
        let rhs_cas = parse_certs_pem(&rhs_ca_bytes)?;
        certificates.extend(rhs_cas);
    }

    certificates = filter_expired_certs(certificates);

    let mut final_certificates = Vec::new();
    // now check for duplicates. n^2, but super simple
    for i in 0..certificates.len() {
        let mut found = false;
        for j in 0..final_certificates.len() {
            if certificates[i] == final_certificates[j] {
                found = true;
                break;
            }
        }
        if !found {
            final_certificates.push(certificates[i].clone());
        }
    }

    let final_ca_bytes = encode_certificates(&final_certificates)?;

    if final_ca_bytes.is_empty() {
        return Ok(None);
    }

    // it makes sense for this list to be static because the combination of sources is only used just before writing and
    // is recalculated
    Ok(Some(Arc::new(StaticCAContent {
        name: "combined".to_string(),
        content: final_ca_bytes,
    })))
}

/// filterExpiredCerts checks are all certificates in the bundle valid, i.e. they have not expired.
/// The function returns new bundle with only valid certificates or error if no valid certificate is found.
/// We allow five minutes of slack for NotAfter comparisons
fn filter_expired_certs(certs: Vec<Vec<u8>>) -> Vec<Vec<u8>> {
    let five_minutes_ago = std::time::SystemTime::now() - Duration::from_secs(5 * 60);

    certs
        .into_iter()
        .filter(|cert_der| {
            if let Ok((_, cert)) = X509Certificate::from_der(cert_der) {
                let not_after = cert.validity().not_after.timestamp();
                let five_min_timestamp = five_minutes_ago
                    .duration_since(std::time::UNIX_EPOCH)
                    .unwrap()
                    .as_secs() as i64;
                not_after > five_min_timestamp
            } else {
                false
            }
        })
        .collect()
}

fn key_fn() -> String {
    // this format matches DeletionHandlingMetaNamespaceKeyFunc for our single key
    format!("{}/{}", CONFIG_MAP_NAMESPACE, CONFIG_MAP_NAME)
}

fn encode_certificates(certs: &[Vec<u8>]) -> Result<Vec<u8>, Box<dyn std::error::Error>> {
    let mut buffer = Vec::new();
    for cert in certs {
        let pem = pem::encode(&pem::Pem {
            tag: "CERTIFICATE".to_string(),
            contents: cert.clone(),
        });
        buffer.extend_from_slice(pem.as_bytes());
    }
    Ok(buffer)
}

fn parse_certs_pem(pem_data: &[u8]) -> Result<Vec<Vec<u8>>, Box<dyn std::error::Error>> {
    let pem_str = std::str::from_utf8(pem_data)?;
    let pems = pem::parse_many(pem_str)?;
    Ok(pems.into_iter().map(|p| p.contents).collect())
}
============================================


use std::net::IpAddr;
use std::sync::{Arc, Mutex};
use std::time::Duration;
use tokio::sync::mpsc;
use tokio::time;
use k8s_openapi::api::core::v1::{
    EndpointPort, Service, ServicePort, ServiceSpec,
};
use k8s_openapi::apimachinery::pkg::apis::meta::v1::ObjectMeta;
use k8s_openapi::apimachinery::pkg::util::intstr::IntOrString;
use kube::{Api, Client, Error as KubeError};
use kube::runtime::reflector::{ObjectRef, Store};

const KUBERNETES_SERVICE_NAME: &str = "kubernetes";

/// Controller is the controller manager for the core bootstrap Kubernetes
/// controller loops, which manage creating the "kubernetes" service and
/// provide the IP repair check on service IPs
pub struct Controller {
    config: Config,
    client: Client,
    service_lister: Store<Service>,
    service_synced: bool,
    lock: Mutex<()>,
    stop_tx: Option<mpsc::Sender<()>>,
}

pub struct Config {
    pub public_ip: IpAddr,
    pub endpoint_reconciler: Box<dyn EndpointReconciler>,
    pub endpoint_interval: Duration,
    
    /// ServiceIP indicates where the kubernetes service will live. It may not be nil.
    pub service_ip: IpAddr,
    pub service_port: i32,
    pub public_service_port: i32,
    pub kubernetes_service_node_port: i32,
}

pub trait EndpointReconciler: Send + Sync {
    fn remove_endpoints(
        &self,
        service_name: &str,
        ip: IpAddr,
        ports: Vec<EndpointPort>,
    ) -> Result<(), Box<dyn std::error::Error>>;
    
    fn reconcile_endpoints(
        &self,
        service_name: &str,
        ip: IpAddr,
        ports: Vec<EndpointPort>,
        reconcile: bool,
    ) -> Result<(), Box<dyn std::error::Error>>;
    
    fn stop_reconciling(&self);
    fn destroy(&self);
}

impl Controller {
    /// New returns a controller for watching the kubernetes service endpoints.
    pub fn new(
        config: Config,
        client: Client,
        service_lister: Store<Service>,
    ) -> Self {
        Controller {
            config,
            client,
            service_lister,
            service_synced: false,
            lock: Mutex::new(()),
            stop_tx: None,
        }
    }

    /// Start begins the core controller loops that must exist for bootstrapping
    /// a cluster.
    pub async fn start(&mut self, mut stop_rx: mpsc::Receiver<()>) {
        if !self.wait_for_cache_sync(&mut stop_rx).await {
            eprintln!("timed out waiting for caches to sync");
            return;
        }

        // Reconcile during first run removing itself until server is ready.
        let endpoint_ports = create_endpoint_port_spec(self.config.public_service_port, "https");
        match self.config.endpoint_reconciler.remove_endpoints(
            KUBERNETES_SERVICE_NAME,
            self.config.public_ip,
            endpoint_ports.clone(),
        ) {
            Ok(_) => {
                eprintln!("Found stale data, removed previous endpoints on kubernetes service, apiserver didn't exit successfully previously");
            }
            Err(e) if !is_not_found(&e) => {
                eprintln!("Error removing old endpoints from kubernetes service: {:?}", e);
            }
            _ => {}
        }

        let (local_stop_tx, mut local_stop_rx) = mpsc::channel(1);
        
        tokio::spawn(async move {
            tokio::select! {
                _ = stop_rx.recv() => {}, // from Start
                _ = local_stop_rx.recv() => {}, // from Stop
            }
        });

        self.run(local_stop_rx).await;
    }

    /// Stop cleans up this API Servers endpoint reconciliation leases so another master can take over more quickly.
    pub async fn stop(&mut self) {
        let _guard = self.lock.lock().unwrap();

        if let Some(stop_tx) = self.stop_tx.take() {
            let _ = stop_tx.send(()).await;
        } else {
            return; // only close once
        }

        let endpoint_ports = create_endpoint_port_spec(self.config.public_service_port, "https");
        let reconciler = &self.config.endpoint_reconciler;
        let public_ip = self.config.public_ip;
        let endpoint_interval = self.config.endpoint_interval;

        let finished = tokio::spawn(async move {
            println!("Shutting down kubernetes service endpoint reconciler");
            reconciler.stop_reconciling();
            if let Err(e) = reconciler.remove_endpoints(
                KUBERNETES_SERVICE_NAME,
                public_ip,
                endpoint_ports,
            ) {
                eprintln!("Unable to remove endpoints from kubernetes service: {:?}", e);
            }
            reconciler.destroy();
        });

        match tokio::time::timeout(2 * endpoint_interval, finished).await {
            Ok(_) => {
                // done
            }
            Err(_) => {
                // don't block server shutdown forever if we can't reach etcd to remove ourselves
                eprintln!("RemoveEndpoints() timed out");
            }
        }
    }

    /// Run periodically updates the kubernetes service
    pub async fn run(&self, mut stop_rx: mpsc::Receiver<()>) {
        // wait until process is ready
        let ready = self.wait_for_ready(&mut stop_rx).await;
        if !ready {
            return;
        }

        let mut interval = time::interval(self.config.endpoint_interval);
        loop {
            tokio::select! {
                _ = interval.tick() => {
                    // Service definition is not reconciled after first
                    // run, ports and type will be corrected only during
                    // start.
                    if let Err(e) = self.update_kubernetes_service(false).await {
                        eprintln!("unable to sync kubernetes service: {:?}", e);
                    }
                }
                _ = stop_rx.recv() => {
                    break;
                }
            }
        }
    }

    /// UpdateKubernetesService attempts to update the default Kube service.
    pub async fn update_kubernetes_service(&self, reconcile: bool) -> Result<(), Box<dyn std::error::Error>> {
        // Update service & endpoint records.
        let (service_ports, service_type) = create_port_and_service_spec(
            self.config.service_port,
            self.config.public_service_port,
            self.config.kubernetes_service_node_port,
            "https",
        );
        
        self.create_or_update_master_service_if_needed(
            KUBERNETES_SERVICE_NAME,
            self.config.service_ip,
            service_ports,
            service_type.clone(),
            reconcile,
        ).await?;
        
        let endpoint_ports = create_endpoint_port_spec(self.config.public_service_port, "https");
        self.config.endpoint_reconciler.reconcile_endpoints(
            KUBERNETES_SERVICE_NAME,
            self.config.public_ip,
            endpoint_ports,
            reconcile,
        )?;
        
        Ok(())
    }

    /// CreateOrUpdateMasterServiceIfNeeded will create the specified service if it
    /// doesn't already exist.
    async fn create_or_update_master_service_if_needed(
        &self,
        service_name: &str,
        service_ip: IpAddr,
        service_ports: Vec<ServicePort>,
        service_type: String,
        reconcile: bool,
    ) -> Result<(), Box<dyn std::error::Error>> {
        let services: Api<Service> = Api::default_namespaced(self.client.clone());
        
        if let Some(s) = self.service_lister.get(&ObjectRef::new(service_name).within("default")) {
            // The service already exists.
            // This path is no executed since 1.17 2a9a9fa, keeping it in case it needs to be revisited
            if reconcile {
                if let Some((svc, true)) = get_master_service_update_if_needed(
                    s,
                    service_ports.clone(),
                    service_type.clone(),
                ) {
                    eprintln!("Resetting master service {:?} to {:?}", service_name, svc);
                    services.replace(service_name, &Default::default(), &svc).await?;
                }
            }
            return Ok(());
        }

        let single_stack = "SingleStack".to_string();
        let mut labels = std::collections::BTreeMap::new();
        labels.insert("provider".to_string(), "kubernetes".to_string());
        labels.insert("component".to_string(), "apiserver".to_string());

        let svc = Service {
            metadata: ObjectMeta {
                name: Some(service_name.to_string()),
                namespace: Some("default".to_string()),
                labels: Some(labels),
                ..Default::default()
            },
            spec: Some(ServiceSpec {
                ports: Some(service_ports.clone()),
                // maintained by this code, not by the pod selector
                selector: None,
                cluster_ip: Some(service_ip.to_string()),
                ip_family_policy: Some(single_stack),
                session_affinity: Some("None".to_string()),
                type_: Some(service_type.clone()),
                ..Default::default()
            }),
            ..Default::default()
        };

        match services.create(&Default::default(), &svc).await {
            Ok(_) => Ok(()),
            Err(KubeError::Api(api_err)) if api_err.code == 409 => {
                // AlreadyExists
                self.create_or_update_master_service_if_needed(
                    service_name,
                    service_ip,
                    service_ports,
                    service_type,
                    reconcile,
                ).await
            }
            Err(e) => Err(Box::new(e)),
        }
    }

    async fn wait_for_cache_sync(&self, stop_rx: &mut mpsc::Receiver<()>) -> bool {
        // Simplified implementation - in real code would wait for informer sync
        true
    }

    async fn wait_for_ready(&self, stop_rx: &mut mpsc::Receiver<()>) -> bool {
        let mut interval = time::interval(Duration::from_millis(100));
        loop {
            tokio::select! {
                _ = interval.tick() => {
                    // Check readiness endpoint
                    // Simplified - in real code would check /readyz
                    return true;
                }
                _ = stop_rx.recv() => {
                    return false;
                }
            }
        }
    }
}

/// createPortAndServiceSpec creates an array of service ports.
/// If the NodePort value is 0, just the servicePort is used, otherwise, a node port is exposed.
fn create_port_and_service_spec(
    service_port: i32,
    target_service_port: i32,
    node_port: i32,
    service_port_name: &str,
) -> (Vec<ServicePort>, String) {
    // Use the Cluster IP type for the service port if NodePort isn't provided.
    // Otherwise, we will be binding the master service to a NodePort.
    let mut service_ports = vec![ServicePort {
        protocol: Some("TCP".to_string()),
        port: service_port,
        name: Some(service_port_name.to_string()),
        target_port: Some(IntOrString::Int(target_service_port)),
        ..Default::default()
    }];
    
    let mut service_type = "ClusterIP".to_string();
    if node_port > 0 {
        service_ports[0].node_port = Some(node_port);
        service_type = "NodePort".to_string();
    }
    
    (service_ports, service_type)
}

/// createEndpointPortSpec creates the endpoint ports
fn create_endpoint_port_spec(endpoint_port: i32, endpoint_port_name: &str) -> Vec<EndpointPort> {
    vec![EndpointPort {
        protocol: Some("TCP".to_string()),
        port: endpoint_port,
        name: Some(endpoint_port_name.to_string()),
        ..Default::default()
    }]
}

/// getMasterServiceUpdateIfNeeded sets service attributes for the given apiserver service.
fn get_master_service_update_if_needed(
    svc: &Service,
    service_ports: Vec<ServicePort>,
    service_type: String,
) -> Option<(Service, bool)> {
    // Determine if the service is in the format we expect
    // (servicePorts are present and service type matches)
    let format_correct = check_service_format(svc, &service_ports, &service_type);
    if format_correct {
        return Some((svc.clone(), false));
    }
    
    let mut updated_svc = svc.clone();
    if let Some(ref mut spec) = updated_svc.spec {
        spec.ports = Some(service_ports);
        spec.type_ = Some(service_type);
    }
    
    Some((updated_svc, true))
}

/// Determine if the service is in the correct format
/// getMasterServiceUpdateIfNeeded expects (servicePorts are correct
/// and service type matches).
fn check_service_format(
    s: &Service,
    ports: &[ServicePort],
    service_type: &str,
) -> bool {
    let spec = match &s.spec {
        Some(spec) => spec,
        None => return false,
    };
    
    if spec.type_.as_deref() != Some(service_type) {
        return false;
    }
    
    let s_ports = match &spec.ports {
        Some(p) => p,
        None => return false,
    };
    
    if ports.len() != s_ports.len() {
        return false;
    }
    
    for (i, port) in ports.iter().enumerate() {
        if port != &s_ports[i] {
            return false;
        }
    }
    
    true
}

fn is_not_found(err: &Box<dyn std::error::Error>) -> bool {
    // Simplified - in real code would check for specific NotFound error
    err.to_string().contains("not found")
}
